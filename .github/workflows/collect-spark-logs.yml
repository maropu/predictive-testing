name: Collect Spark GitHub logs

on:
  push:
    branches:
      - master
  # schedule:
  # - cron: '0 */2 * * *'

jobs:
  collect-spark-logs:
    runs-on: ubuntu-latest
    env:
      python: 3.6
    strategy:
      fail-fast: false
    steps:
      - name: Checkout predictive-testing repository
        uses: actions/checkout@v2
        # In order to fetch changed files
        with:
          fetch-depth: 0
      - name: Install Python ${{ env.python }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ env.python }}
          architecture: x64
      - name: Install Python packages (Python ${{ env.python }})
        run: python -m pip install -r ./bin/requirements.txt
      - name: Run a script to collect GitHub logs in apache/spark
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          SINCE_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ" -d '1 month ago'`
          ./bin/collect_github_logs.py --output output --github-token "${GITHUB_TOKEN}" --github-owner apache --github-repo spark --since "${SINCE_DATE}"
      - name: Upload collected logs as artifact
        if: success()
        uses: actions/upload-artifact@v2
        with:
          name: spark-github-logs
          path: ./output/*
      - name: Upload INFO logs as artifact
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: debug-logs
          path: ./output/debug-info.log
